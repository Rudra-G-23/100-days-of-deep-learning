{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Hello Data Points \ud83d\udc4b","text":""},{"location":"#roadmap","title":"Roadmap","text":"<ul> <li> <p> Roadmap     ---</p> <p>We Follow this Roadmap\ud83d\udc26\u200d\ud83d\udd25</p> <p></p> </li> <li> <p> Content Inspiration     ---</p> <p>My lovely Nitish Sir's Playlist\ud83d\udc9c</p> <p></p> </li> </ul>"},{"location":"backpropagation/the-how/","title":"Backpropagation (THE HOW)","text":"\\[     \\begin{array}{l}     \\text{Backpropagation Algorithm} \\\\     \\text{epochs} = 5 \\to (5) \\\\     \\text{for } i \\text{ in range(epochs):} \\\\     \\quad \\text{for } j \\text{ in range}(\\mathbf{X}.\\text{shape}[0]): \\\\     \\quad \\quad \\to \\text{ Select 1 row (random)} \\\\     \\quad \\quad \\to \\text{ Predict (using forward prop)} \\\\     \\quad \\quad \\to \\text{ Calculate loss (using loss function } \\to \\text{ mse)} \\\\     \\quad \\quad \\to \\text{ Update weights and bias using GD} \\\\     \\quad \\quad \\quad \\mathbf{W}_{\\text{new}} = \\mathbf{W}_{\\text{old}} - \\eta \\frac{\\partial L}{\\partial \\mathbf{W}} \\\\     \\quad \\to \\text{ Calculate avg loss for the epoch}     \\end{array} \\]"},{"location":"backpropagation/the-what/","title":"Backpropagation (THE WHAT)","text":""},{"location":"backpropagation/the-what/#steps","title":"Steps","text":"<ol> <li>init w, b: \u2192 Random (w=1,b=0)</li> <li>select a point (now)</li> <li>predict/Do Forward prop. (Dot prd)</li> <li>Choose a loss function</li> <li>weight &amp; bias update (Gradient Descent)</li> </ol> \\[ W_{\\text{new}} = W_{\\text{old}} - \\eta \\frac{\\partial L}{\\partial W_{\\text{old}}} \\] \\[ b_{\\text{new}} = b_{\\text{old}} - \\eta \\frac{\\partial L}{\\partial b_{\\text{old}}} \\] \\[ \\]"},{"location":"backpropagation/the-what/#partial-derivative","title":"Partial Derivative","text":"<ul> <li> Delete the some derivative</li> </ul> <p>We Need to find out this 9 derivative</p> \\[ \\frac{\\partial L}{\\partial w_{11}'}, \\frac{\\partial L}{\\partial w_{21}'}, \\frac{\\partial L}{\\partial w_{31}'}, \\frac{\\partial L}{\\partial w_{41}'}, \\frac{\\partial L}{\\partial b_{11}'} \\mid \\frac{\\partial L}{\\partial w_{12}'}, \\frac{\\partial L}{\\partial w_{22}'}, \\frac{\\partial L}{\\partial w_{32}'}, \\frac{\\partial L}{\\partial w_{42}'}, \\frac{\\partial L}{\\partial b_{12}'} \\] \\[ \\frac{\\partial L}{\\partial w_{11}^2}, \\frac{\\partial L}{\\partial w_{21}^2}, \\frac{\\partial L}{\\partial w_{12}^2}, \\frac{\\partial L}{\\partial w_{22}^2}, \\frac{\\partial L}{\\partial b_{21}} \\mid \\frac{\\partial L}{\\partial w_{31}^2}, \\frac{\\partial L}{\\partial w_{41}^2}, \\frac{\\partial L}{\\partial w_{32}^2}, \\frac{\\partial L}{\\partial w_{42}^2}, \\frac{\\partial L}{\\partial b_{22}} \\]"},{"location":"backpropagation/the-what/#chain-rule","title":"Chain Rule","text":"\\[ \\begin{aligned} \\frac{\\partial L}{\\partial w_{11}^2} &amp;= \\frac{\\partial L}{\\partial \\hat{Y}} \\cdot \\frac{\\partial \\hat{Y}}{\\partial w_{11}^2} \\quad (\\text{Chain Rule}) \\\\ \\\\ \\text{where } \\frac{\\partial L}{\\partial \\hat{Y}} &amp;= \\frac{\\partial}{\\partial \\hat{Y}} (Y - \\hat{Y})^2 = -2(Y - \\hat{Y}) \\\\ \\\\ \\text{and } \\frac{\\partial \\hat{Y}}{\\partial w_{11}^2} &amp;= \\frac{\\partial}{\\partial w_{11}^2} (O_{11} w_{11}^2 + O_{12} w_{21}^2 + b_{21}) = O_{11} \\\\ \\\\ \\text{Thus, } \\frac{\\partial L}{\\partial w_{11}^2} &amp;= -2(Y - \\hat{Y}) O_{11} \\end{aligned} \\] <ol> <li> <p>Derivative of Loss w.r.t. Prediction \\(\\hat{Y}\\):</p> \\[ \\begin{aligned} \\frac{\\partial L}{\\partial \\hat{Y}} &amp;= \\frac{\\partial}{\\partial \\hat{Y}} (Y - \\hat{Y})^2 = -2(Y - \\hat{Y}) \\end{aligned} \\] </li> <li> <p>Derivative of Prediction w.r.t. Weight  \\({w_{11}^2}\\):     $$     \\begin{aligned}     \\frac{\\partial \\hat{Y}}{\\partial w_{11}^2} &amp;= \\frac{\\partial}{\\partial w_{11}^2} (O_{11} w_{11}^2 + O_{12} w_{21}^2 + b_{21}) = O_{11}     \\end{aligned}     $$</p> </li> <li> <p>Final Result (Chain Rule Applied):</p> \\[ \\begin{aligned} \\frac{\\partial L}{\\partial w_{11}^2} &amp;= -2(Y - \\hat{Y}) O_{11} \\end{aligned} \\] </li> </ol> \\[ \\begin{aligned} \\frac{\\partial L}{\\partial w_{21}^2} &amp;= \\frac{\\partial L}{\\partial \\hat{Y}} \\cdot \\frac{\\partial \\hat{Y}}{\\partial w_{21}^2} \\\\ \\\\ \\text{where } \\frac{\\partial \\hat{Y}}{\\partial w_{21}^2} &amp;= \\frac{\\partial}{\\partial w_{21}^2} (O_{11} w_{11}^2 + O_{12} w_{21}^2 + b_{21}) = O_{12} \\\\ \\\\ \\text{Thus, } \\frac{\\partial L}{\\partial w_{21}^2} &amp;= -2(Y - \\hat{Y}) O_{12} \\end{aligned} \\] \\[ \\begin{aligned} \\frac{\\partial L}{\\partial b_{21}} &amp;= \\frac{\\partial L}{\\partial \\hat{Y}} \\cdot \\frac{\\partial \\hat{Y}}{\\partial b_{21}} \\\\ \\\\ \\text{where } \\frac{\\partial \\hat{Y}}{\\partial b_{21}} &amp;= \\frac{\\partial}{\\partial b_{21}} (O_{11} w_{11}^2 + O_{12} w_{21}^2 + b_{21}) = 1 \\\\ \\\\ \\text{Thus, } \\frac{\\partial L}{\\partial b_{21}} &amp;= -2(Y - \\hat{Y}) \\end{aligned} \\] \\[ \\] \\[ \\] \\[ \\] <p>Above are</p> <p>This are the w1 , w2 and b</p>"},{"location":"backpropagation/the-what/#layer-1","title":"Layer 1","text":"\\[ \\frac{\\partial L}{\\partial w_{11}'} = \\frac{\\partial L}{\\partial \\hat{Y}} \\cdot \\frac{\\partial \\hat{Y}}{\\partial O_{11}} \\cdot \\frac{\\partial O_{11}}{\\partial w_{11}'} = -2(Y - \\hat{Y}) w_{11}^2 x_{i1} \\] \\[ \\frac{\\partial L}{\\partial w_{21}'} = \\frac{\\partial L}{\\partial \\hat{Y}} \\cdot \\frac{\\partial \\hat{Y}}{\\partial O_{11}} \\cdot \\frac{\\partial O_{11}}{\\partial w_{21}'} = -2(Y - \\hat{Y}) w_{11}^2 x_{i2} \\] \\[ \\frac{\\partial L}{\\partial b_{11}'} = \\frac{\\partial L}{\\partial \\hat{Y}} \\cdot \\frac{\\partial \\hat{Y}}{\\partial O_{11}} \\cdot \\frac{\\partial O_{11}}{\\partial b_{11}'} = -2(Y - \\hat{Y}) w_{11}^2 \\]"},{"location":"backpropagation/the-what/#derivatives-with-respect-to-layer-2-inputs-o-1i","title":"Derivatives with respect to Layer 2 Inputs (O 1i)","text":"\\[ \\begin{aligned} \\frac{\\partial \\hat{Y}}{\\partial O_{11}} &amp;= \\frac{\\partial}{\\partial O_{11}} [W_{11}^2 O_{11} + W_{21}^2 O_{12} + b_{21}] = W_{11}^2 \\\\ \\frac{\\partial \\hat{Y}}{\\partial O_{12}} &amp;= \\frac{\\partial}{\\partial O_{12}} [W_{11}^2 O_{11} + W_{21}^2 O_{12} + b_{21}] = W_{21}^2 \\end{aligned} \\] \\[ \\begin{aligned} \\frac{\\partial O_{11}}{\\partial w_{11}'} &amp;= \\frac{\\partial}{\\partial w_{11}'} [x_{i1} w_{11}' + x_{i2} w_{21}' + b_{11}'] = x_{i1} \\quad \\text{(iq)} \\\\ \\frac{\\partial O_{11}}{\\partial w_{21}'} &amp;= \\frac{\\partial}{\\partial w_{21}'} [x_{i1} w_{11}' + x_{i2} w_{21}' + b_{11}'] = x_{i2} \\quad \\text{(cgpa)} \\\\ \\frac{\\partial O_{11}}{\\partial b_{11}'} &amp;= \\frac{\\partial}{\\partial b_{11}'} [x_{i1} w_{11}' + x_{i2} w_{21}' + b_{11}'] = 1 \\end{aligned} \\]"},{"location":"backpropagation/the-what/#layer-2","title":"Layer 2","text":"\\[ \\frac{\\partial L}{\\partial w_{12}'} = \\frac{\\partial L}{\\partial \\hat{Y}} \\cdot \\frac{\\partial \\hat{Y}}{\\partial O_{12}} \\cdot \\frac{\\partial O_{12}}{\\partial w_{12}'} = -2(Y - \\hat{Y}) W_{21}^2 X_{i1} \\] \\[ \\frac{\\partial L}{\\partial w_{22}'} = \\frac{\\partial L}{\\partial \\hat{Y}} \\cdot \\frac{\\partial \\hat{Y}}{\\partial O_{12}} \\cdot \\frac{\\partial O_{12}}{\\partial w_{22}'} = -2(Y - \\hat{Y}) W_{21}^2 X_{i2} \\] \\[ \\frac{\\partial L}{\\partial b_{12}'} = \\frac{\\partial L}{\\partial \\hat{Y}} \\cdot \\frac{\\partial \\hat{Y}}{\\partial O_{12}} \\cdot \\frac{\\partial O_{12}}{\\partial b_{12}'} = -2(Y - \\hat{Y}) W_{21}^2 \\] \\[ \\begin{aligned} \\frac{\\partial O_{12}}{\\partial w_{12}'} &amp;= \\frac{\\partial}{\\partial w_{12}'} \\left[ X_{i1} w_{12}' + X_{i2} w_{22}' + b_{12}' \\right] = X_{i1} \\\\ \\frac{\\partial O_{12}}{\\partial w_{22}'} &amp;= \\frac{\\partial}{\\partial w_{22}'} \\left[ X_{i1} w_{12}' + X_{i2} w_{22}' + b_{12}' \\right] = X_{i2} \\\\ \\frac{\\partial O_{12}}{\\partial b_{12}'} &amp;= \\frac{\\partial}{\\partial b_{12}'} \\left[ X_{i1} w_{12}' + X_{i2} w_{22}' + b_{12}' \\right] = 1 \\end{aligned} \\] \\[ \\begin{array}{l} \\text{epocs} = 1000 \\\\ \\text{1) for } i \\text{ in range(n):} \\\\ \\quad \\text{a) one student } \\to \\text{ forward prop} \\\\ \\quad \\text{b) loss calculate} \\\\ \\quad \\text{c) Adjust all weight \\&amp; bias} \\\\ \\quad W_{\\text{new}} = W_{\\text{old}} - \\eta \\frac{\\partial L}{\\partial W_{\\text{old}}} \\end{array} \\]"},{"location":"backpropagation/the-what/#final-derivate","title":"Final Derivate","text":"\\[ \\] \\[ \\] \\[ \\] \\[ \\] \\[ \\]"},{"location":"backpropagation/the-what/#final-steps","title":"Final Steps","text":"\\[ \\] \\[ \\] \\[ \\] \\[ \\] \\[ \\]"},{"location":"backpropagation/the-why/","title":"Backpropagation (THE WHY)","text":"<p>-- FEW CONCEPT</p>"},{"location":"basic-of-dl/introduction/","title":"Deep Learning \u2014 clear, compact guide","text":""},{"location":"basic-of-dl/introduction/#1-what-is-deep-learning","title":"1 \u2014 What is Deep Learning?","text":"<ul> <li> <p>Deep Learning (DL) is a subfield of machine learning (ML) based on artificial neural networks with many layers and automatic representation learning.</p> </li> <li> <p>Instead of manually designing features, DL models learn hierarchical features from raw inputs: early layers detect low-level patterns (edges, textures), middle layers combine these into parts (shapes), and later layers form high-level concepts (faces, objects).</p> </li> <li> <p>Short definition: Deep learning = neural network models with multiple layers that automatically learn features from data.</p> </li> </ul>"},{"location":"basic-of-dl/introduction/#example-cat-vs-dog","title":"Example (cat vs dog)","text":"<ul> <li>Traditional ML workflow: collect features (color histograms, SIFT, HOG), hand-craft feature engineering, feed into classifier (SVM, Random Forest).</li> <li>Deep learning workflow: feed raw images into a CNN; early conv layers learn edges; deeper layers learn shapes and parts; final fully connected or global pooling + softmax classifies dog vs cat automatically.</li> </ul>"},{"location":"basic-of-dl/introduction/#2-big-picture-dl-vs-ml","title":"2 \u2014 Big picture: DL vs ML","text":"Aspect Machine Learning (classical) Deep Learning Feature engineering Manual \u2014 domain experts design features Automatic \u2014 representation learning inside network Data requirement Works well with small/moderate datasets Usually data-hungry; benefits from large datasets &amp; transfer learning Hardware needs CPU often sufficient GPUs/TPUs recommended for training; faster inference with optimized hardware Model complexity Often simple, interpretable (decision trees, linear models) Large, many parameters \u2014 often less interpretable Training time Usually shorter Can be long (hours\u2192weeks) depending on model/data/hardware Typical use cases tabular data, small datasets, interpretable models Image, audio, text, video, large-scale tasks Interpretability Easier to explain Harder \u2014 requires explainability tools Example algorithms SVM, Random Forest, Logistic Regression CNNs, RNNs, Transformers, GANs When to choose Small data, need interpretability or fast training Large data, high accuracy, complex patterns"},{"location":"basic-of-dl/introduction/#3-why-is-deep-learning-famous-now-5-pillars","title":"3 \u2014 Why is Deep Learning famous now? (5 pillars)","text":""},{"location":"basic-of-dl/introduction/#1-data-scale-availability","title":"1) Data (scale &amp; availability)","text":"<ul> <li>The explosion of digital data (images, video, text, logs, sensor data, audio) supplies DL models with the huge datasets they need.</li> <li> <p>Public benchmark datasets and large corpora enabled fast progress and reproducible comparisons.</p> <p>Famous datasets (examples):</p> <ul> <li>Images: ImageNet, Microsoft COCO</li> <li>Video: YouTube-8M (large collection of labeled video)</li> <li>Text / QA: SQuAD, Wikipedia dumps (for language modeling)</li> <li>Audio: Librispeech, Google AudioSet</li> </ul> </li> </ul>"},{"location":"basic-of-dl/introduction/#2-hardware-improvements","title":"2) Hardware improvements","text":"<ul> <li>GPUs (NVIDIA + CUDA) massively parallelize matrix ops required by DL.</li> <li>TPUs, FPGAs, ASICs and specialized edge chips accelerate training and inference.</li> <li>Moore\u2019s law + specialized hardware reduced training time and cost.</li> </ul>"},{"location":"basic-of-dl/introduction/#3-libraries-software-ecosystems","title":"3) Libraries &amp; software ecosystems","text":"<ul> <li>High-level libraries (TensorFlow, Keras, PyTorch) made model building and experimentation easy.</li> <li>Rich ecosystems (pretrained models, tutorials, community repos) accelerated adoption.</li> </ul>"},{"location":"basic-of-dl/introduction/#4-architectural-breakthroughs","title":"4) Architectural breakthroughs","text":"<ul> <li>Convolutional Neural Networks (CNNs) for images (AlexNet, VGG, ResNet, EfficientNet).</li> <li>Recurrent/sequence models and later Transformers for NLP (LSTM \u2192 Transformer \u2192 BERT / GPT).</li> <li>Specialized models for generation and translation (U-Net, GANs, Diffusion models).</li> <li>Object detection (YOLO, SSD) and segmentation (Mask R-CNN).</li> </ul>"},{"location":"basic-of-dl/introduction/#5-research-community","title":"5) Research &amp; community","text":"<ul> <li>Open research, code releases, benchmarks and competitive platforms (e.g., Kaggle) created fast iteration loops.</li> <li>Transfer learning, pretraining, and model hubs made it practical to apply DL even with limited resources.</li> </ul>"},{"location":"basic-of-dl/introduction/#4-short-historical-timeline-key-milestones","title":"4 \u2014 Short historical timeline (key milestones)","text":"<ul> <li>1943 \u2014 McCulloch &amp; Pitts: artificial neuron concept</li> <li>1958 \u2014 Perceptron (Rosenblatt)</li> <li>1986 \u2014 Backpropagation popularized (Rumelhart et al.)</li> <li>1998 \u2014 LeNet (early CNN for digits)</li> <li>2006 \u2014 Deep learning renaissance: unsupervised pretraining and deeper networks</li> <li>2012 \u2014 AlexNet: big win on ImageNet \u2192 modern DL boom</li> <li>2014\u20132015 \u2014 ResNet, advances in architectures and training</li> <li>2017 \u2014 Transformer (attention mechanism) \u2014 revolutionized NLP</li> <li>2018+ \u2014 BERT, GPT series, diffusion models, and large pretrained models</li> </ul>"},{"location":"basic-of-dl/introduction/#5-important-architectures-and-typical-applications","title":"5 \u2014 Important architectures and typical applications","text":"<ul> <li>CNNs (Convolutional Neural Networks) \u2014 image classification, detection, segmentation (ResNet, EfficientNet).</li> <li>RNNs / LSTM / GRU \u2014 sequence modeling (older; now often replaced).</li> <li>Transformers \u2014 language understanding and generation (BERT, GPT), also used for images (ViT).</li> <li>U-Net \u2014 image segmentation, biomedical imaging.</li> <li>GANs / Diffusion Models \u2014 image generation and synthesis.</li> <li>YOLO / SSD / Faster R-CNN \u2014 object detection.</li> <li>WaveNet / wav2vec / Whisper \u2014 speech synthesis/recognition.</li> </ul>"},{"location":"basic-of-dl/types-of-dl/","title":"Foundations of Deep Learning","text":""},{"location":"basic-of-dl/types-of-dl/#1-types-of-neural-networks","title":"1. Types of Neural Networks","text":"<p>Neural networks come in many forms, depending on the data type and problem.</p> Type Key Idea Typical Applications ANN (Artificial Neural Network / MLP) Fully connected layers; each neuron connected to all in next layer. Tabular data, basic classification/regression. PNN (Probabilistic Neural Network) Based on Bayesian classification; uses probability distribution functions. Medical diagnosis, pattern recognition (small datasets). CNN (Convolutional Neural Network) Uses convolution filters for local feature extraction. Image classification (ResNet, EfficientNet), object detection (YOLO), segmentation (U-Net). RNN (Recurrent Neural Network) Feedback connections \u2192 memory of sequences. Time series, NLP (older models before Transformers). LSTM / GRU Special RNN variants to handle long-term dependencies. Text, speech, sequential prediction. Autoencoders Encode input into low-dimensional representation, then reconstruct. Dimensionality reduction, denoising, anomaly detection. GAN (Generative Adversarial Network) Two networks (Generator vs Discriminator) in competition. Image synthesis, deepfakes, data augmentation. Transformers (modern) Attention mechanism, no recurrence/convolution. NLP (BERT, GPT), Vision Transformers (ViT), multimodal AI."},{"location":"basic-of-dl/types-of-dl/#2-historical-timeline","title":"2. Historical Timeline","text":""},{"location":"basic-of-dl/types-of-dl/#1960s-early-enthusiasm","title":"1960s \u2014 Early enthusiasm","text":"<ul> <li>Perceptron (Rosenblatt, 1958\u20131960s): First implementation of a neural network.</li> <li>Similar to a simplified model of a human neuron.</li> <li>Limitation discovered later: Could not solve XOR function (non-linear separability).</li> </ul>"},{"location":"basic-of-dl/types-of-dl/#1969-first-ai-winter","title":"1969 \u2014 First AI Winter","text":"<ul> <li>Minsky &amp; Papert published Perceptrons (book), proving perceptron\u2019s limitations.</li> <li>Funding cuts, enthusiasm dropped \u2192 1<sup>st</sup> AI Winter.</li> <li>No good algorithms, no hardware, very little data.</li> </ul>"},{"location":"basic-of-dl/types-of-dl/#1980s-revival","title":"1980s \u2014 Revival","text":"<ul> <li>Geoffrey Hinton &amp; team (1986): popularized Backpropagation \u2192 enabled training of multi-layer networks.</li> <li>Networks could now learn internal representations (features automatically).</li> <li>1989: Yann LeCun applied CNNs to handwritten digit recognition \u2192 landmark success in computer vision (precursor of LeNet).</li> </ul>"},{"location":"basic-of-dl/types-of-dl/#1990s-2nd-ai-winter","title":"1990s \u2014 2<sup>nd</sup> AI Winter","text":"<ul> <li>Still limited by hardware (no GPUs), data scarcity, poor initialization methods.</li> <li>Training deep networks was difficult \u2192 interest shifted to SVMs, Random Forests, etc.</li> </ul>"},{"location":"basic-of-dl/types-of-dl/#2006-the-deep-learning-name-appears","title":"2006 \u2014 The \u201cDeep Learning\u201d name appears","text":"<ul> <li>Hinton et al. introduced Deep Belief Networks using unsupervised pre-training.</li> <li>Helped overcome optimization issues.</li> <li>Sparked renewed interest \u2192 term Deep Learning became popular.</li> </ul>"},{"location":"basic-of-dl/types-of-dl/#2010-start-of-the-modern-dl-era","title":"2010 \u2014 Start of the modern DL era","text":"<ul> <li>DL used for image classification tasks with improved hardware (GPUs).</li> <li>Data became abundant (ImageNet dataset launched in 2009).</li> </ul>"},{"location":"basic-of-dl/types-of-dl/#2012-breakthrough-deep-learning-gpu","title":"2012 \u2014 Breakthrough: Deep Learning + GPU","text":"<ul> <li>AlexNet (Krizhevsky et al.) won ImageNet challenge, reducing error rate by a huge margin.</li> <li>Used ReLU, dropout, GPU acceleration.</li> <li>Triggered massive industry adoption \u2192 the final rise of DL.</li> </ul>"},{"location":"basic-of-dl/types-of-dl/#20142016-expansion","title":"2014\u20132016 \u2014 Expansion","text":"<ul> <li>GANs (2014) introduced by Goodfellow \u2014 generative AI boom.</li> <li>ResNet (2015): skip connections \u2192 very deep networks trainable.</li> <li>AlphaGo (2016): DeepMind\u2019s system beat human champions \u2192 milestone in reinforcement learning.</li> </ul>"},{"location":"basic-of-dl/types-of-dl/#2017present-transformer-modern-era","title":"2017\u2013Present \u2014 Transformer &amp; modern era","text":"<ul> <li>Attention is All You Need (2017): introduced the Transformer architecture, removing recurrence.</li> <li>BERT, GPT (2018\u20132020+): revolutionized NLP with pretraining + fine-tuning.</li> <li>Vision Transformers (ViT, 2020) showed attention works for vision too.</li> <li>Diffusion models (2021+): DALL\u00b7E, Stable Diffusion, MidJourney \u2192 state-of-the-art image generation.</li> <li>Modern DL = multimodal (text + image + audio), massive pretrained models, efficient deployment (quantization, distillation).</li> </ul>"},{"location":"help/keyboard-shortcuts/","title":"Keyboard Shortcuts","text":""},{"location":"help/keyboard-shortcuts/#keyboard-shortcuts","title":"Keyboard shortcuts","text":"<p>Global Search</p> <ul> <li>Down , Up : select next / previous result</li> <li>Esc , Tab : close search dialog</li> <li>Enter : follow selected result</li> </ul> <p>Page Navigation</p> <ul> <li>F , S , / : open search dialog</li> <li>P , , : go to previous page</li> <li>N , . : go to next page</li> </ul> <p>:</p>"},{"location":"mlp/forward-propagation/","title":"Forward Propagation","text":""},{"location":"mlp/forward-propagation/#diagram","title":"Diagram","text":"<ul> <li> Add the neural network</li> </ul>"},{"location":"mlp/forward-propagation/#layer-1","title":"Layer 1","text":"\\[ W^TX + b \\] \\[ L_1 = \\begin{bmatrix} W_{11} &amp; W_{12} &amp; W_{13} \\\\ W_{21} &amp; W_{22} &amp; W_{23} \\\\ W_{31} &amp; W_{32} &amp; W_{33} \\\\ W_{41} &amp; W_{42} &amp; W_{43} \\end{bmatrix}^T \\cdot \\begin{bmatrix} X_{i1} \\\\ X_{i2} \\\\ X_{i3} \\\\ X_{i4} \\end{bmatrix} + \\begin{bmatrix} b_{i1} \\\\ b_{i2} \\\\ b_{i3} \\end{bmatrix} \\] \\[ L_1 = \\begin{bmatrix} W_{11}' X_{i1} + W_{12}' X_{i2} + W_{13}' X_{i3} + W_{14}' X_{i4} \\\\ W_{21}' X_{i1} + W_{22}' X_{i2} + W_{23}' X_{i3} + W_{24}' X_{i4} \\\\ W_{31}' X_{i1} + W_{32}' X_{i2} + W_{33}' X_{i3} + W_{34}' X_{i4} \\end{bmatrix} + \\begin{bmatrix} b_{i1} \\\\ b_{i2} \\\\ b_{i3} \\end{bmatrix} \\] \\[ L_1 = \\sigma \\left( \\begin{bmatrix} W_{11}' X_{i1} + W_{12}' X_{i2} + W_{13}' X_{i3} + W_{14}' X_{i4} + b_{i1} \\\\ W_{21}' X_{i1} + W_{22}' X_{i2} + W_{23}' X_{i3} + W_{24}' X_{i4} + b_{i2} \\\\ W_{31}' X_{i1} + W_{32}' X_{i2} + W_{33}' X_{i3} + W_{34}' X_{i4} + b_{i3} \\end{bmatrix} \\right) = \\begin{bmatrix} O_{i1} \\\\ O_{i2} \\\\ O_{i3} \\end{bmatrix} \\]"},{"location":"mlp/forward-propagation/#layer-2","title":"Layer 2","text":"\\[ \\mathbf{L}_2 = \\sigma \\left( \\begin{bmatrix} W_{11}^2 &amp; W_{21}^2 &amp; W_{31}^2 \\\\ W_{12}^2 &amp; W_{22}^2 &amp; W_{32}^2 \\end{bmatrix}^T \\cdot \\begin{bmatrix} O_1 \\\\ O_2 \\\\ O_3 \\end{bmatrix} + \\begin{bmatrix} b_{21} \\\\ b_{22} \\end{bmatrix} \\right) = \\begin{bmatrix} O'_{21} \\\\ O'_{22} \\end{bmatrix} \\] \\[ \\mathbf{L}_2 = \\sigma \\left( \\begin{bmatrix} W_{11}^2 O_1 + W_{21}^2 O_2 + W_{31}^2 O_3 + b_{21} \\\\ W_{12}^2 O_1 + W_{22}^2 O_2 + W_{32}^2 O_3 + b_{22} \\end{bmatrix} \\right) = \\begin{bmatrix} O'_{21} \\\\ O'_{22} \\end{bmatrix} \\] \\[ \\] \\[ \\]"},{"location":"mlp/forward-propagation/#layer-3","title":"Layer 3","text":"\\[ \\hat{Y} = \\sigma \\left( \\begin{bmatrix} W_{11}^3 \\\\ W_{21}^3 \\end{bmatrix}^T \\cdot \\begin{bmatrix} O_{21} \\\\ O_{22} \\end{bmatrix} + \\begin{bmatrix} b_{31} \\end{bmatrix} \\right) \\] \\[ \\hat{Y} = \\sigma \\left( \\left[ W_{11}^3 O_{21} + W_{21}^3 O_{22} + b_{31} \\right] \\right) \\] \\[ \\] \\[ \\]"},{"location":"mlp/forward-propagation/#one-line","title":"One line","text":"\\[ \\mathbf{a}^{[1]} = \\sigma (\\mathbf{a}^{[0]} \\mathbf{W}^{[1]} + \\mathbf{b}^{[1]}) \\] \\[ \\mathbf{a}^{[2]} = \\sigma (\\mathbf{a}^{[1]} \\mathbf{W}^{[2]} + \\mathbf{b}^{[2]}) \\] \\[ \\mathbf{a}^{[3]} = \\sigma (\\mathbf{a}^{[2]} \\mathbf{W}^{[3]} + \\mathbf{b}^{[3]}) \\] <ul> <li> This one line code is missing </li> </ul>"},{"location":"mlp/mlp-intuition/","title":"MLP Intuition","text":""},{"location":"mlp/mlp-intuition/#mlp-with-sigmoid","title":"MLP with Sigmoid","text":""},{"location":"mlp/mlp-intuition/#different-method-to-create-architecture","title":"Different method to create Architecture","text":""},{"location":"mlp/mlp-notation/","title":"MLP Notation","text":""},{"location":"mlp/mlp-notation/#one-hidden-layer","title":"One hidden layer","text":""},{"location":"mlp/mlp-notation/#two-hidden-layer","title":"Two hidden layer","text":""},{"location":"perceptron/gradient-descent-for-perceptron/","title":"Gradient Descent For Perceptron","text":""},{"location":"perceptron/gradient-descent-for-perceptron/#algorithm","title":"Algorithm","text":"<p>Algorithm</p> \\[ \\begin{array}{l} \\text{Gradient Descent} \\\\ \\\\ L = \\underset{w, w_2, b}{\\text{argmin}} \\\\ \\\\ L = \\frac{1}{n} \\sum_{i=1}^{n} \\max(0, -Y_i f(x_i)) \\\\ \\text{where } f(x_i) = w_1 x_{i1} + w_2 x_{i2} + b \\\\ \\\\ \\text{for } i \\text{ in epoch} \\\\ \\quad w_1 = w_1 + \\eta \\frac{\\partial L}{\\partial w_1} \\\\ \\quad w_2 = w_2 + \\eta \\frac{\\partial L}{\\partial w_2} \\\\ \\quad b = b + \\eta \\frac{\\partial L}{\\partial b} \\end{array} \\] Partial Derivative \\[ \\frac{\\partial L}{\\partial w_1} = \\frac{\\partial L}{\\partial f(x_i)} \\cdot \\frac{\\partial f(x_i)}{\\partial w_1} \\] <ul> <li> <p> Partial Derivative of Loss w.r.t. \\(f(x_i)\\)     ---</p> \\[ \\frac{\\partial L}{\\partial f(x_i)} = \\begin{cases} 0 &amp; \\text{if } 1 - Y_i f(x_i) \\leq 0 \\\\ -Y_i &amp; \\text{if } 1 - Y_i f(x_i) &gt; 0 \\end{cases} \\] </li> <li> <p> Partial Derivative of \\(f(x_i)\\) w.r.t. \\(w_1\\)     ---</p> \\[ \\frac{\\partial f(x_i)}{\\partial w_1} = \\frac{\\partial}{\\partial w_1} (w_1 x_{i1} + w_2 x_{i2} + b) = x_{i1} \\] </li> </ul> Similarly for the \\(w_1\\), \\(w_2\\), and bias (\\(b\\)) \\[ \\begin{array}{l} \\frac{\\partial L}{\\partial w_1} = \\begin{cases} 0 &amp; \\text{if } Y_i f(x_i) \\geq 0 \\\\ -Y_i x_{i1} &amp; \\text{if } Y_i f(x_i) &lt; 0 \\end{cases} \\\\ \\\\ \\frac{\\partial L}{\\partial w_2} = \\begin{cases} 0 &amp; \\text{if } Y_i f(x_i) \\geq 0 \\\\ -Y_i x_{i2} &amp; \\text{if } Y_i f(x_i) &lt; 0 \\end{cases} \\\\ \\\\ \\frac{\\partial L}{\\partial b} = \\begin{cases} 0 &amp; \\text{if } Y_i f(x_i) \\geq 0 \\\\ -Y_i &amp; \\text{if } Y_i f(x_i) &lt; 0 \\end{cases} \\end{array} \\]"},{"location":"perceptron/more-loss-function/","title":"More Loss Function","text":"<pre><code>graph LR\n%% Inputs\nX1([x\u2081])\nX2([x\u2082])\nB([1])\n\n%% Neuron and output\nSUM([\u2211])\nF([f])\nY([y\u1d62])\n\n%% Labeled edges only\nX1 -- w\u2081 --&gt; SUM\nX2 -- w\u2082 --&gt; SUM\nB  -- b  --&gt; SUM\n\nSUM --&gt; F --&gt; Y</code></pre> <p>When to use &amp; What</p> \\[ \\begin{array}{c|c|c|c} \\text{Loss function} &amp; \\text{Activation} &amp; \\text{Output} &amp; \\text{where to use} \\\\ \\hline \\text{Hinge Loss} &amp; \\text{Step} &amp; \\text{Perceptron} &amp; \\text{Binary classification} \\\\ \\hline \\text{Log-loss} \\newline (\\text{Binary cross-entropy}) &amp; \\text{Sigmoid} &amp; \\text{Logistic Regression} &amp; \\text{Binary class} \\\\ \\hline \\text{Categorical} \\newline \\text{Cross entropy} &amp; \\text{Softmax} &amp; \\text{Softmax Regression} &amp; \\text{Multiclass class} \\\\ \\hline \\text{MSE} &amp; \\text{linear} &amp; \\text{linear Regression} &amp; \\text{linear Regression} \\\\ \\end{array} \\]"},{"location":"perceptron/perceptron-basic/","title":"Perceptron","text":"<pre><code>graph LR\n%% Inputs\nX1([x\u2081])\nX2([x\u2082])\nB([1])\n\n%% Neuron and output\nSUM([\u2211])\nF([f])\nY([y\u1d62])\n\n%% Labeled edges only\nX1 -- w\u2081 --&gt; SUM\nX2 -- w\u2082 --&gt; SUM\nB  -- b  --&gt; SUM\n\nSUM --&gt; F --&gt; Y</code></pre>"},{"location":"perceptron/perceptron-basic/#parts","title":"Parts","text":"<ul> <li>This is the summation \\(z = w_1x_1  + w_2x_2 + b\\)</li> <li>In Activation Function We can use any kind of functions like Step Function, Sigmoid Function</li> </ul>"},{"location":"perceptron/perceptron-basic/#formula","title":"Formula","text":"<p>Info</p> <p>The summation for a simple model can be expressed as: \\(z = w_1x_1 + w_2x_2 + b\\)</p> <p>Activation Function : In Activation Function We can use any kind of functions like Step Function, Sigmoid Function</p> Summation Examples iq cgpa Placed 78 55 1 45 34 0 <p>Let's assume the following weights and bias:</p> <ul> <li>\\(w_1 = 1\\)</li> <li>\\(w_2 = 2\\)</li> <li> <p>\\(b = 6\\)</p> <ul> <li>If the value is \\(\\ge\\) then placed</li> <li>If the value is \\(&lt;\\) then not placed</li> </ul> </li> </ul> Row 1Row 2 <p><pre><code>(78 * 1) + (55 * 2) + 6\n</code></pre> Output<pre><code>78 + 110 + 6 = 194 \n</code></pre> The value 194 is \\(\\ge\\) the placement condition, so the predicted outcome is Placed (1).</p> <p><pre><code>(45 * 1) + (34 * 2) + 6\n</code></pre> Output<pre><code>45 + 68 + 6 = 119\n</code></pre> The value 119 is \\(\\ge\\) the placement condition, so the predicted outcome is Placed (1).</p>"},{"location":"perceptron/perceptron-basic/#neuron-vs-perceptron","title":"Neuron Vs Perceptron","text":""},{"location":"perceptron/perceptron-basic/#interpretation","title":"Interpretation","text":""},{"location":"perceptron/perceptron-basic/#geometric-intuition","title":"Geometric Intuition","text":"Explanation <ol> <li> <p>Linear Combination / Pre-activation (\\(Z\\)):</p> \\[Z = w_1 x_1 + w_2 x_2 + b\\] </li> <li> <p>Step Activation Function (\\(Y\\)):</p> \\[Y = f(Z) = \\begin{cases} 1 &amp; Z \\geq 0 \\\\ 0 &amp; Z &lt; 0 \\end{cases}\\] </li> <li> <p>General Form of a Line (Substitution):</p> <p>Let \\(w_1 = A, w_2 = B, b = C\\) and \\(x_1 = x, x_2 = Y\\), </p> <p>then:</p> \\[\\text{General form of line: } Ax + By + C = 0\\] </li> <li> <p>Region Classification based on the Line:</p> \\[\\begin{cases} \\geq 0 &amp; \\text{+ve Region} \\\\ &lt; 0 &amp; \\text{-ve Region} \\end{cases}\\] </li> </ol>"},{"location":"perceptron/perceptron-basic/#limitation","title":"Limitation","text":"<ul> <li> It works only Linear and sort of linear </li> <li> Not work on non-linear line</li> </ul>"},{"location":"perceptron/perceptron-loss-function/","title":"Perceptron Loss Function","text":""},{"location":"perceptron/perceptron-loss-function/#problem-with-the-perceptron-trick","title":"Problem with the Perceptron Trick","text":"<p>Problem With Perceptron</p> <p></p>"},{"location":"perceptron/perceptron-loss-function/#gradient-descent","title":"Gradient Descent","text":"<p>Gradient Descent</p> \\[ L(w_1, w_2, b) = \\frac{1}{n} \\sum_{i=1}^{n} L(Y_i, f(x_i)) + \\alpha R(w_1, w_2)  \\] <ul> <li>Loss function term: \\(L(Y_i, f(x_i)) = \\max\\left(0, Y_i f(x_i)\\right)\\)</li> <li>Regularization term: \\(\\alpha R(w_1, w_2)\\)</li> <li>Here \\(f(x) = w_0 x_0 + w_1 x_1 + w_2 x_2 + b\\)</li> </ul> <p>Loss Function</p> \\[ L = \\frac{1}{n} \\sum_{i=1}^{n} L(Y_i, f(x_i)) \\quad \\text{(\\# mean loss)} \\] \\[ \\begin{array}{l} \\text{Let } -Y_i f(x_i) = X \\\\ \\text{then } \\max(0, X) \\end{array} \\] \\[ \\max(0, X) = \\begin{cases} X &amp; \\text{if } X \\geq 0 \\quad (\\text{or } -Y_i f(x_i) \\geq 0) \\\\ 0 &amp; \\text{if } X &lt; 0 \\quad (\\text{or } -Y_i f(x_i) &lt; 0) \\end{cases} \\]"},{"location":"perceptron/perceptron-loss-function/#simplified-version","title":"Simplified Version","text":"<p>Simple Version</p> Data Points <p></p> \\[ \\begin{bmatrix} X_{11} &amp; X_{12} \\\\ X_{21} &amp; X_{22} \\end{bmatrix} \\] \\[ L = \\frac{1}{2} \\left[ \\max(0, 1 - Y_1 f(x_1)) + \\max(0, 1 - Y_2 f(x_2)) \\right] \\] \\[ \\begin{array}{c|c|c|c|c|c|c} \\text{Point} &amp; Y_i &amp; \\hat{Y}_i &amp; Y_i \\cdot f(x_i) &amp; -Y_i f(x_i) &amp; \\max(0, 1 - Y_i f(x_i)) &amp; \\text{Output} \\\\ \\hline \\text{P1} &amp; 1 &amp; 1 &amp; +\\text{ve} &amp; -\\text{ve} &amp; \\max(0, \\text{some } -\\text{ve value}) &amp; 0 \\\\ \\text{P2} &amp; 1 &amp; -1 &amp; -\\text{ve} &amp; +\\text{ve} &amp; \\max(0, \\text{some } +\\text{ve value}) &amp; \\text{some } +\\text{ve value} \\\\ \\text{P3} &amp; -1 &amp; 1 &amp; -\\text{ve} &amp; +\\text{ve} &amp; \\max(0, \\text{some } +\\text{ve value}) &amp; \\text{some } +\\text{ve value} \\\\ \\text{P4} &amp; -1 &amp; -1 &amp; +\\text{ve} &amp; -\\text{ve} &amp; \\max(0, \\text{some } -\\text{ve value}) &amp; 0 \\\\ \\end{array} \\]"},{"location":"perceptron/perceptron-trick-algorithm/","title":"Perceptron Trick Algorithm","text":""},{"location":"perceptron/perceptron-trick-algorithm/#general-equation","title":"General Equation","text":"<p>General Equation</p> <ul> <li> <p> Input Data</p> \\[ \\begin{array}{c|c|c|c} \\mathbf{x}_0 &amp; \\mathbf{x}_1 \\text{(cgpa)} &amp; \\mathbf{x}_2 \\text{(iq)} &amp; \\mathbf{Y} \\text{(placed)} \\\\ \\hline 1 &amp; 7.5 &amp; 81 &amp; 1 \\\\ 1 &amp; 7.5 &amp; 109 &amp; 1 \\\\ 1 &amp; 7.0 &amp; 81 &amp; 0 \\end{array} \\] </li> <li> <p> Weights and Bias Analogy</p> \\[ \\begin{aligned} Ax + By + C &amp;= 0 \\\\ w_1 &amp;= A \\\\ w_2 &amp;= B \\\\ w_0 &amp;= \\text{bias} = C \\end{aligned} \\] </li> <li> <p> Summation Equation</p> \\[ \\begin{aligned} w_0 x_0 + w_1 x_1 + w_2 x_2 &amp;= 0 \\\\ \\sum_{i=0}^{n} w_i x_i &amp;= 0 \\end{aligned} \\] </li> <li> <p> Vectorized Form</p> \\[ \\begin{bmatrix} w_0 &amp; w_1 &amp; w_2 \\end{bmatrix} \\begin{bmatrix} x_0 \\\\ x_1 \\\\ x_2 \\end{bmatrix} = 0 \\] </li> </ul>"},{"location":"perceptron/perceptron-trick-algorithm/#process","title":"Process","text":"<p>Process</p> \\[ \\begin{array}{l} \\text{epoch } 1000, \\quad \\eta = 0.01 \\\\  \\text{for } i \\text{ in range (epochs):} \\\\ \\quad \\text{1. Randomly select a student (or point).} \\\\ \\quad \\text{2. if } \\mathbf{x}_i \\in \\text{N and } \\sum_{i=0}^{n} w_i x_i \\geq 0 \\quad (\\text{ -ve point, fall in +ve region}) \\\\ \\quad \\quad w_{\\text{new}} = w_{\\text{old}} - \\eta \\mathbf{x}_i \\\\ \\quad \\text{3. if } \\mathbf{x}_i \\in \\text{P and } \\sum_{i=0}^{n} w_i x_i &lt; 0 \\quad (\\text{+ve point, fall in -ve region}) \\\\ \\quad \\quad w_{\\text{new}} = w_{\\text{old}} + \\eta \\mathbf{x}_i \\end{array} \\] Explanation <ol> <li> <p>Learning Rate:</p> \\[ \\text{epoch } = 1000 \\quad \\eta = 0.01 \\] </li> <li> <p>Condition for Negative Class Point (N) Misclassified as Positive (\u22650)</p> \\[ \\mathbf{x}_i \\in \\text{N and } \\sum_{i=0}^{n} w_i x_i \\geq 0 \\] </li> <li> <p>Weight Update (Correction 1 - Subtract x_i)</p> \\[ \\quad \\quad w_{\\text{new}} = w_{\\text{old}} - \\eta \\mathbf{x}_i  \\] </li> <li> <p>Condition for Positive Class Point (P) Misclassified as Negative (&lt;0)</p> \\[ \\quad \\quad w_{\\text{new}} = w_{\\text{old}} + \\eta \\mathbf{x}_i \\] </li> <li> <p>Weight Update (Correction 2 - Add x_i)</p> \\[ \\mathbf{x}_i \\in \\text{P and } \\sum_{i=0}^{n} w_i x_i &lt; 0 \\quad (\\text{fall in -ve region}) \\] </li> </ol>"},{"location":"perceptron/perceptron-trick-algorithm/#simplified-algo","title":"Simplified Algo","text":"<ul> <li> <p> Perceptron Update Rule     ---</p> \\[ w_{\\text{new}} = w_{\\text{old}} + \\eta (Y_i - \\hat{Y_i}) X_i \\] </li> <li> <p> Weight Update Scenarios     ---</p> \\[ \\begin{array}{c|c|c|c} \\text{Formula} &amp; Y_i - \\hat{Y_i} &amp; \\hat{Y_i} &amp; Y_i \\\\ \\hline w_{\\text{new}} = w_{\\text{old}} &amp; 0 &amp; 1 &amp; 1 \\\\ w_{\\text{new}} = w_{\\text{old}} &amp; 0 &amp; 0 &amp; 0 \\\\ w_{\\text{new}} = w_{\\text{old}} + \\eta X_i &amp; 1 &amp; 0 &amp; 1 \\\\ w_{\\text{new}} = w_{\\text{old}} - \\eta X_i &amp; -1 &amp; 1 &amp; 0 \\\\ \\end{array} \\] </li> <li> <p> Epoch Iteration     ---</p> \\[ \\begin{array}{l} \\text{for } i \\text{ in range (epochs):} \\\\ \\quad \\text{select random student} \\\\ \\quad w_{\\text{new}} = w_{\\text{old}} + \\eta (Y_i - \\hat{Y_i}) X_i \\end{array} \\] </li> </ul>"},{"location":"perceptron/perceptron-trick/","title":"Perceptron Trick","text":""},{"location":"perceptron/perceptron-trick/#what-is-perceptron-trick","title":"What is Perceptron Trick ?","text":"<p>Perceptron Trick</p> <p></p>"},{"location":"perceptron/perceptron-trick/#how-it-work","title":"How it work ?","text":"<p>How perceptron Works</p> <p></p> <p></p>"},{"location":"perceptron/perceptron-trick/#how-to-know-which-is-ve-ve-region-for-a-point","title":"How to know which is +ve &amp; -ve region for a point ?","text":"<p>Find the Region</p> <p></p>"},{"location":"perceptron/perceptron-trick/#transformations","title":"Transformations","text":"For A For B For C"},{"location":"perceptron/problem-with-perceptron/","title":"Problem with Perceptron","text":""},{"location":"perceptron/problem-with-perceptron/#or","title":"OR","text":""},{"location":"perceptron/problem-with-perceptron/#nor","title":"NOR","text":""},{"location":"perceptron/problem-with-perceptron/#and","title":"AND","text":""},{"location":"perceptron/problem-with-perceptron/#xor","title":"XOR","text":""},{"location":"perceptron/problem-with-perceptron/#xnor","title":"XNOR","text":""}]}